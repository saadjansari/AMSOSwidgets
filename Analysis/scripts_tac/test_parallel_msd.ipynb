{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from numba import njit,jit\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import yaml\n",
    "import networkx as nx\n",
    "import scipy\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', family='sans-serif')\n",
    "plt.rc('xtick', labelsize='x-small')\n",
    "plt.rc('ytick', labelsize='x-small')\n",
    "plt.close('all')\n",
    "cols = ['c','m','b','g','r','y','k']\n",
    "\n",
    "# Define paths\n",
    "savepath = Path(\"/Users/saadjansari/Desktop/Meetings/Flatiron/Flatiron 201112\")\n",
    "path_prefix = Path(\"/Users/saadjansari/Documents/Projects/Results/AMSOS\")\n",
    "simpaths = [\n",
    "    path_prefix / \"Tactoids/scan_filamin_6400/run/f5_merged\",\n",
    "    path_prefix / \"Tactoids/scan_filamin_6400/run/f10_merged\",\n",
    "]\n",
    "# simpaths = [\n",
    "#     path_prefix / \"Tactoids/n25600/f5_merged\",\n",
    "# ]\n",
    "cols = cols[0:len(simpaths)]\n",
    "# resolve paths\n",
    "for spath in simpaths:\n",
    "    spath.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def unfold_trajectories(crds, boxsize):\n",
    "    # unfolded trajectory via the shortest route\n",
    "    # expect input: crds = [time, particle, dim]\n",
    "    crds2 = np.zeros_like(crds)\n",
    "    crds2[0,:,:] = crds[0,:,:]\n",
    "    for idx in np.arange(crds.shape[-1]):\n",
    "        for ipart in np.arange(crds.shape[1]):\n",
    "            \n",
    "            # find amount particle travels frame to frame\n",
    "            dist = nb_diff( crds[:,ipart,idx])\n",
    "            k = np.sign( dist) * np.floor( np.absolute(dist)/(0.51*boxsize[idx]))\n",
    "            dist -= k*boxsize[idx]\n",
    "            crds2[1:,ipart,idx] = dist.cumsum()+crds[0,ipart,idx]\n",
    "    return crds2\n",
    "\n",
    "@njit\n",
    "def nb_diff(x):\n",
    "    return x[1:] - x[:-1]\n",
    "\n",
    "def get_boxsize_pbc(spath, conf=False):\n",
    "    # Read yaml config file to extract information about space\n",
    "    # If confinement is True, use a cylindrical confinement in XY plane, but full box size in Z\n",
    "    with open( spath / 'RunConfig.yaml') as yf:\n",
    "        rconfig = yaml.safe_load( yf)\n",
    "        \n",
    "    box_size = np.array( rconfig['simBoxHigh']) - np.array( rconfig['simBoxLow'])\n",
    "    if conf:\n",
    "        box_size[0] = 2*box_size[0]\n",
    "        box_size[1] = 2*box_size[1]\n",
    "    return box_size\n",
    "\n",
    "def find_frames(spath):\n",
    "    \n",
    "    def fileKey(f):\n",
    "        return int( f.parts[-1].split('_')[-1].split('.dat')[0] )\n",
    "    file_s_last = sorted( list(spath.glob('**/SylinderAscii*')), key=fileKey)\n",
    "    file_p_last = sorted( list(spath.glob('**/ProteinAscii*')), key=fileKey)\n",
    "    return file_s_last, file_p_last\n",
    "\n",
    "def read_dat_sylinder_centers( fname):\n",
    "    # Read a SylinderAscii_X.dat file\n",
    "\n",
    "    # open the file and read the lines\n",
    "    with open(fname, 'r') as file1:\n",
    "        filecontent = file1.readlines()\n",
    "\n",
    "        # Initialize numpy arrays for data\n",
    "        pos0 = np.zeros( (len(filecontent)-2,3))\n",
    "        pos1 = np.zeros( (len(filecontent)-2,3))\n",
    "        c = np.zeros( (len(filecontent)-2,3))\n",
    "\n",
    "        # Delete the first two lines because they dont have any data\n",
    "        filecontent[0:2] = []\n",
    "        for idx,line in enumerate(filecontent):\n",
    "\n",
    "            # Split the string with space-delimited and convert strings into useful data types\n",
    "            data = line.split()\n",
    "\n",
    "            dat = np.array( list(map(float,data[2::])) )\n",
    "            c[idx,:] = (dat[1:4] + dat[4::])/2            \n",
    "\n",
    "    return c\n",
    "\n",
    "def get_nodes_in_clusters( nodes, edge0, edge1, min_size_ratio=0.1):\n",
    "    # Get largesst connected component\n",
    "    # nodes is a list of integers representing node indices\n",
    "    # edge0 / edge1 are the list of nodes that each edge connects to.\n",
    "    # Indices whose values are -1 are ignored in both edge0 and edge1.\n",
    "\n",
    "    # Create a graph for filaments\n",
    "    g = nx.Graph()\n",
    "    g.add_nodes_from( nodes)\n",
    "\n",
    "    # add edges to the graph\n",
    "    for e0,e1 in zip( edge0,edge1):\n",
    "        if e0 != -1 and e1 != -1:\n",
    "            g.add_edge(e0, e1)\n",
    "\n",
    "    # find connected component largest\n",
    "    cc_sort = sorted(nx.connected_components(g), key=len, reverse=True)\n",
    "    cc_large = [ii for ii in cc_sort if len(ii) > min_size_ratio*len(nodes)]\n",
    "    cc = []\n",
    "    for clus in cc_large:\n",
    "        cc+=clus\n",
    "\n",
    "    # also get a boolean array representing nodes that are in the largest cc\n",
    "    cc_bool = np.zeros(len(nodes), dtype=bool)\n",
    "    cc_bool[ cc] = True\n",
    "    return cc, cc_bool\n",
    "\n",
    "def read_dat_sylinder( fname):\n",
    "    # Read a SylinderAscii_X.dat file\n",
    "\n",
    "    # open the file and read the lines\n",
    "    with open(fname, 'r') as file1:\n",
    "        filecontent = file1.readlines()\n",
    "\n",
    "        # Initialize numpy arrays for data\n",
    "        gids = np.zeros( len(filecontent)-2, dtype=int)\n",
    "        rad = np.zeros(len(filecontent)-2)\n",
    "        pos0 = np.zeros( (len(filecontent)-2,3))\n",
    "        pos1 = np.zeros( (len(filecontent)-2,3))\n",
    "        ort = np.zeros( (len(filecontent)-2,3))\n",
    "\n",
    "        # Delete the first two lines because they dont have any data\n",
    "        filecontent[0:2] = []\n",
    "        for idx,line in enumerate(filecontent):\n",
    "\n",
    "            # Split the string with space-delimited and convert strings into useful data types\n",
    "            data = line.split()\n",
    "            gids[idx] = int(data[1])\n",
    "\n",
    "            dat = np.array( list(map(float,data[2::])) )\n",
    "            rad[idx] = dat[0]\n",
    "            pos0[idx,:] = dat[1:4]\n",
    "            pos1[idx,:] = dat[4::]\n",
    "            xi = pos1[idx,:] - pos0[idx,:]\n",
    "            ort[idx,:] =  xi/np.sqrt(xi.dot(xi))\n",
    "\n",
    "    # Store data as a dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'gid': gids,\n",
    "        'radius' : rad,\n",
    "        'pos0' : list(pos0),\n",
    "        'pos1': list(pos1),\n",
    "        'orientation': list(ort)\n",
    "        })\n",
    "    return df\n",
    "\n",
    "def read_dat_protein( fname):\n",
    "    # Read a ProetinAscii_X.dat file\n",
    "\n",
    "    # open the file and read the lines\n",
    "    with open(fname, 'r') as file1:\n",
    "        filecontent = file1.readlines()\n",
    "\n",
    "        # Delete the first two lines because they dont have any data\n",
    "        filecontent[0:2] = []\n",
    "\n",
    "        # Initialize numpy arrays for data\n",
    "        gids = np.zeros( len(filecontent), dtype=int)\n",
    "        pos0 = np.zeros( (len(filecontent),3))\n",
    "        pos1 = np.zeros( (len(filecontent),3))\n",
    "        link0 = np.zeros( len(filecontent), dtype=int)\n",
    "        link1 = np.zeros( len(filecontent), dtype=int)\n",
    "\n",
    "        for idx,line in enumerate(filecontent):\n",
    "\n",
    "            # Split the string with space-delimited and convert strings into useful data types\n",
    "            data = line.split()\n",
    "            # pdb.set_trace()\n",
    "            gids[idx] = int(data[1])\n",
    "            link0[idx] = int(data[9])\n",
    "            link1[idx] = int(data[10])\n",
    "            dat = np.array( list(map(float,data[2:9])) )\n",
    "            pos0[idx,:] = dat[1:4]\n",
    "            pos1[idx,:] = dat[4::]\n",
    "\n",
    "    # Store data as a dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'gid': gids,\n",
    "        'pos0' : list(pos0),\n",
    "        'pos1': list(pos1),\n",
    "        'link0': link0,\n",
    "        'link1': link1\n",
    "        })\n",
    "    return df\n",
    "\n",
    "def load_trajectories(spath):\n",
    "\n",
    "    # Load data\n",
    "    boxsize = get_boxsize_pbc( spath)\n",
    "\n",
    "    # Get files for frames\n",
    "    files_syl, files_prot = find_frames( spath)\n",
    "    nT = len(files_syl)\n",
    "    nDim = 3\n",
    "\n",
    "    # number of particles\n",
    "    nPar = len( read_dat_sylinder_centers(files_syl[0]))\n",
    "\n",
    "    # Load position centers and store them in a numpy array\n",
    "    pos = np.zeros( (nT, nPar, nDim))\n",
    "    for idx,fil in enumerate( files_syl):\n",
    "        pos[idx,:,:] = read_dat_sylinder_centers(fil)\n",
    "\n",
    "    # Load 10 frames for sylinder, protein to get cluster elements\n",
    "    frr = np.array( np.floor(np.linspace(0,nT-1, 10)), dtype=int)\n",
    "    cc_bool = np.ones((1,nPar),dtype=bool)\n",
    "    for fr in frr:\n",
    "        \n",
    "        df_sylinder = read_dat_sylinder(files_syl[fr])\n",
    "        df_protein = read_dat_protein( files_prot[fr])\n",
    "        cc, cc_booll = get_nodes_in_clusters(\n",
    "                df_sylinder.gid.tolist(),\n",
    "                df_protein.link0.tolist(),\n",
    "                df_protein.link1.tolist(),\n",
    "                min_size_ratio=0.1)\n",
    "        cc_bool = np.logical_and(cc_bool, cc_booll)\n",
    "    \n",
    "    cc = np.argwhere(cc_bool)[:,1].tolist()\n",
    "    return pos[:,cc,:], boxsize\n",
    "\n",
    "@njit\n",
    "def msd_traj_1d(pos):\n",
    "    result = np.zeros_like(pos)\n",
    "    deltastop = pos.shape[0]\n",
    "    for traj in range(pos.shape[1]):\n",
    "#         for dim in range(pos.shape[2]):\n",
    "        for delta in range(1,deltastop):\n",
    "            thisresult = 0\n",
    "            for i in range(delta,deltastop):\n",
    "#                 thisresult += (pos[traj,i,dim] - pos[traj,i-delta,dim])**2\n",
    "                thisresult += (pos[i,traj] - pos[i-delta,traj])**2\n",
    "#             result[traj,delta,dim] = thisresult / (deltastop - delta)\n",
    "            result[delta,traj] = thisresult / (deltastop - delta)\n",
    "    return result\n",
    "\n",
    "@njit\n",
    "def msd_traj_3d(pos):\n",
    "    msd = np.zeros_like(pos)\n",
    "    for idx in np.arange(pos.shape[-1]):\n",
    "        msd[:,:,idx] = msd_traj_1d(pos[:,:,idx])\n",
    "    return msd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time = 101.84080171585083\n"
     ]
    }
   ],
   "source": [
    "msds = []\n",
    "\n",
    "# Analyze each sim\n",
    "spath = simpaths[0]\n",
    "\n",
    "t0 = time.time()\n",
    "pos, boxsize = load_trajectories(spath)\n",
    "print('Elapsed time = {}'.format(time.time()-t0))\n",
    "\n",
    "# for spath in simpaths:\n",
    "\n",
    "#     # Load trajectory\n",
    "#     pos, boxsize = load_trajectories(spath)\n",
    "    \n",
    "#     # Unfold trajectory\n",
    "#     pos_full = unfold_trajectories(pos, boxsize)\n",
    "    \n",
    "#     # Calculate MSD\n",
    "#     msds.append( msd_traj_3d(pos_full) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(6,4))\n",
    "for spath, msd, col in zip(simpaths, msds, cols):\n",
    "    \n",
    "    # Plot MSD_z\n",
    "    ax.plot( np.mean(msd[:,:,2], axis=1), label='{0}_Z'.format(spath.name), ls='-', color=col)\n",
    "    \n",
    "    ax.plot( \n",
    "        np.mean( 0.5*(msd[:,:,0] + msd[:,:,1]), axis=1), \n",
    "        label='{0}_XY'.format(spath.name), ls='--', color=col)\n",
    "    \n",
    "plt.legend()\n",
    "ax.set(xlabel=r'timelag ($\\tau$)', ylabel=r'$MSD$ ($\\mu m^2$)')\n",
    "plt.savefig( savepath/\"Tac_msd.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cores = multiprocessing.cpu_count()\n",
    "num_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5 s ± 102 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "inputs = range(1000000) \n",
    "def processInput(i):\n",
    "    return i * i\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "%timeit Parallel(n_jobs=num_cores)(delayed(processInput)(i) for i in inputs)\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179 ms ± 2.72 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit [processInput(i) for i in inputs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type '_asyncio.Future' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-21d7619f1ab4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_trajectories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Elapsed time = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-21d7619f1ab4>\u001b[0m in \u001b[0;36mload_trajectories\u001b[0;34m(spath)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# number of particles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mnPar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mread_dat_sylinder_centers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles_syl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# Load position centers and store them in a numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type '_asyncio.Future' has no len()"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "def background(f):\n",
    "    def wrapped(*args, **kwargs):\n",
    "        return asyncio.get_event_loop().run_in_executor(None, f, *args, **kwargs)\n",
    "\n",
    "    return wrapped\n",
    "\n",
    "@background\n",
    "def read_dat_sylinder_centers( fname):\n",
    "    # Read a SylinderAscii_X.dat file\n",
    "\n",
    "    # open the file and read the lines\n",
    "    with open(fname, 'r') as file1:\n",
    "        filecontent = file1.readlines()\n",
    "\n",
    "        # Initialize numpy arrays for data\n",
    "        pos0 = np.zeros( (len(filecontent)-2,3))\n",
    "        pos1 = np.zeros( (len(filecontent)-2,3))\n",
    "        c = np.zeros( (len(filecontent)-2,3))\n",
    "\n",
    "        # Delete the first two lines because they dont have any data\n",
    "        filecontent[0:2] = []\n",
    "        for idx,line in enumerate(filecontent):\n",
    "\n",
    "            # Split the string with space-delimited and convert strings into useful data types\n",
    "            data = line.split()\n",
    "\n",
    "            dat = np.array( list(map(float,data[2::])) )\n",
    "            c[idx,:] = (dat[1:4] + dat[4::])/2            \n",
    "\n",
    "    return c\n",
    "\n",
    "def load_trajectories(spath):\n",
    "\n",
    "    # Load data\n",
    "    boxsize = get_boxsize_pbc( spath)\n",
    "\n",
    "    # Get files for frames\n",
    "    files_syl, files_prot = find_frames( spath)\n",
    "    nT = len(files_syl)\n",
    "    nDim = 3\n",
    "\n",
    "    # number of particles\n",
    "    nPar = len( read_dat_sylinder_centers(files_syl[0]))\n",
    "\n",
    "    # Load position centers and store them in a numpy array\n",
    "    pos = np.zeros( (nT, nPar, nDim))\n",
    "    for idx,fil in enumerate( files_syl):\n",
    "        pos[idx,:,:] = read_dat_sylinder_centers(fil)\n",
    "\n",
    "    # Load 10 frames for sylinder, protein to get cluster elements\n",
    "    frr = np.array( np.floor(np.linspace(0,nT-1, 10)), dtype=int)\n",
    "    cc_bool = np.ones((1,nPar),dtype=bool)\n",
    "    for fr in frr:\n",
    "        \n",
    "        df_sylinder = read_dat_sylinder(files_syl[fr])\n",
    "        df_protein = read_dat_protein( files_prot[fr])\n",
    "        cc, cc_booll = get_nodes_in_clusters(\n",
    "                df_sylinder.gid.tolist(),\n",
    "                df_protein.link0.tolist(),\n",
    "                df_protein.link1.tolist(),\n",
    "                min_size_ratio=0.1)\n",
    "        cc_bool = np.logical_and(cc_bool, cc_booll)\n",
    "    \n",
    "    cc = np.argwhere(cc_bool)[:,1].tolist()\n",
    "    return pos[:,cc,:], boxsize\n",
    "\n",
    "t0 = time.time()\n",
    "pos, boxsize = load_trajectories(spath)\n",
    "print('Elapsed time = {}'.format(time.time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
